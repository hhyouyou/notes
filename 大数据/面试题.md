



#### 数仓 VS 数据湖

数仓：基于模型的存储系统，用于存储结构化数据，通常包含以及经过清洗和转换的数据

数据湖：基于原始数据的存储系统，可以存储结构化数据和非结构化数据，不需要预定义数据模型，更加灵活的处理数据。





#### ETL的流程

ETL是指将数据从源系统中提取，转换并加载到目标系统中的过程

* 提取： 从数据源提取数据
* 转换：对提取的数据进行清洗、过滤、转换、聚合等操作
* 加载：将处理后的数据加载到目标系统中



#### OLAP VS OLTP

OLAP(联机分析处理)：数据分析和查询，需要处理  大量数据和复杂查询

OLTP(联机事务处理)：事务处理，插入、更新、删除数据，需要快速响应和高并发性能





#### 维度建模VS事实建模

维度建模：将数据存储在以维度为核心的星型或雪花模型中，维度包括描述业务过程中的各种数据，例如时间、地点、产品、客户等。

事实建模：将数据存储在以事实表为核心的模型中，事实表包含了度量值和指标，例如销售额、订单数量、用户访问量等。

维度建模更适合于需要快速查询和分析的场景，而事实建模更适合于需要进行更复杂的数据挖掘和分析。





#### Hadoop核心组件和功能

Hadoop是一个开源的大数据处理框架。核心组件包括以下三个

* HDFS(分布式文件系统)：用于存储大规模数据的分布式文件系统，提供高可靠和容错性。
* MapReduce: 用于将大规模数据分布式处理的编程模型和计算框架，通常用于批量数据处理
* YARN(Yet Another Resource Negotiator) ： 用于资源管理和作业调度的集群管理系统，可以支持各种类型的应用程序



#### 简述数仓架构的组成和特点

* 数据源： 从各种数据源中提取数据，例如传感器、数据库、文件等（web->sls->oss,sdk->web->kafka）
* ETL系统：对提取的数据进行清洗、转换、处理（shell + Azkaban）
* 数据仓库：包含清洗、转换和聚合的数据，用于支持分析和查询（hdfs）
* OLAP引擎：用于支持多维数据分析和查询，通常包括查询语言、查询引擎、缓存等组件 (Presto 、hive)
* 可视化工具：用于将数据仓库中的数据可视化，例如报表、dashboard、chart等 (superset)



#### 数据质量的定义和评估指标



数据质量是指数据的适用性、准确性、完整性、一致性、时效性等方面的度量

* 准确性：数据是否正确、完整、可靠、可验证（比如，上报的数据格式是否准确、内容是否完整、整体数据量是否稳定，等方面）
* 完整性：数据是否包含所有需要的信息，是否有遗漏
* 一致性：数据是否与其他数据源或系统中的数据一致
* 时效性：数据是否及时、有效、最新（比如系统的版本信息，上报状态及时）
* 可理解性：数据是否易于理解和解释



#### 数据治理的定义和目标

元数据收集/标签化数据/数据处理流程

数据治理是指一组管理数据资源的规则、标准和流程，以确保数据质量、安全性、可靠性和可管理性。

* 保证数据质量和完整性
* 保护数据安全和隐私
* 提高数据价值和可用性
* 降低数据管理成本和风险
* 支持数据共享和协作





#### 什么是 Spark？它是用来做什么的？

Spark 是一个基于内存的分布式计算引擎，可以加速大数据处理。它支持多种数据处理工作负载，包括批处理、流处理、机器学习和图形处理。

1. Spark 的优点是什么？

Spark 的优点包括：

- 高性能：Spark 可以使用内存计算，因此比基于磁盘的 Hadoop MapReduce 更快。
- 简单易用：Spark API 简单易用，容易学习和使用。
- 强大的生态系统：Spark 生态系统包括许多开源工具和库，包括 Spark SQL、Spark Streaming、MLlib 和 GraphX。
- 可扩展性：Spark 可以在大规模集群上运行，能够扩展到数千台机器。

#### 什么是 RDD？

RDD 是 Spark 中的核心数据结构，代表一个不可变的、可分区的、可并行操作的数据集合。RDD 可以包含任何类型的对象，包括 Java 和 Scala 中的原始类型、数组和用户定义的对象。

#### Spark 中的哪些组件用于数据处理？

Spark 中有许多组件可以用于数据处理，包括：

- Spark Core：Spark 的核心组件，提供分布式任务调度、内存计算和容错等功能。
- Spark SQL：Spark 的 SQL 引擎，支持使用 SQL 查询结构化数据。
- Spark Streaming：Spark 的流处理引擎，可以对实时数据流进行处理。
- MLlib：Spark 的机器学习库，提供常见的机器学习算法和工具。
- GraphX：Spark 的图形处理库，支持图形算法和图形数据处理。

#### Spark 支持哪些数据源？

Spark 支持多种数据源，包括：

- HDFS：Hadoop 分布式文件系统。
- S3：亚马逊的云存储服务。
- Hive：Hadoop 的数据仓库。
- JDBC：Java 数据库连接。
- Cassandra：分布式 NoSQL 数据库。



#### 如何在 Spark 中缓存数据？

在 Spark 中，可以使用 `cache()` 方法将 RDD 或 DataFrame 缓存在内存中。缓存的数据可以在多个操作之间重复使用，从而提高性能。在缓存大型数据集时，可以使用 `persist()` 方法将数据缓存到磁盘上。

#### 如何调整 Spark 中的任务并发度？

在 Spark 中，可以通过调整分区数来调整任务并发度。可以使用 `repartition()` 或 `coalesce()` 方法增加或减少分区数。在 Spark SQL 中，可以通过调整数据源的并发度来调整任务并发度。

另外，可以通过设置 Spark 的配置参数来控制任务并发度。例如，可以使用 `spark.default.parallelism` 参数来设置默认的任务并发度。

#### 什么是 Spark Streaming？

Spark Streaming 是一个用于处理实时数据流的组件。它可以将实时数据流分成一系列小批量数据，并将它们作为 RDD 处理。Spark Streaming 可以与 Kaf ka、Flume、HDFS 和其他流式数据源集成。

#### 什么是 Spark SQL？

Spark SQL 是 Spark 中的 SQL 引擎，可以使用 SQL 查询结构化数据。Spark SQL 支持多种数据源，包括 Parquet、Avro、JSON 和 Hive 表。Spark SQL 还支持使用 Spark RDD 和 DataFrame API 进行编程。













+